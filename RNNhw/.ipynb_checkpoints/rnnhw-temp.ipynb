{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character level language model - Dinosaurus land\n",
    "\n",
    "Welcome to Dinosaurus Island! 65 million years ago, dinosaurs existed, and in this assignment they are back. You are in charge of a special task. Leading biology researchers are creating new breeds of dinosaurs and bringing them to life on earth, and your job is to give names to these dinosaurs. If a dinosaur does not like its name, it might go beserk, so choose wisely! \n",
    "\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/dino.jpg\" style=\"width:250;height:300px;\">\n",
    "\n",
    "</td>\n",
    "\n",
    "</table>\n",
    "\n",
    "Luckily you have learned some deep learning and you will use it to save the day. Your assistant has collected a list of all the dinosaur names they could find, and compiled them into this [dataset](dinos.txt). (Feel free to take a look by clicking the previous link.) To create new dinosaur names, you will build a character level language model to generate new names. Your algorithm will learn the different name patterns, and randomly generate new names. Hopefully this algorithm will keep you and your team safe from the dinosaurs' wrath! \n",
    "\n",
    "By completing this assignment you will learn:\n",
    "\n",
    "- How to store text data for processing using an RNN \n",
    "- How to synthesize data, by sampling predictions at each time step and passing it to the next RNN-cell unit\n",
    "- How to build a character-level text generation recurrent neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# torch.set_printoptions(linewidth=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# hidden_size = 100\n",
    "class DinosDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with open('RNNhw\\dinos.txt') as f:\n",
    "            content = f.read().lower()\n",
    "            self.vocab = sorted(set(content))\n",
    "            self.vocab_size = len(self.vocab)\n",
    "            self.lines = content.splitlines()\n",
    "\n",
    "        self.ch_to_idx = {}\n",
    "        self.idx_to_ch = {}\n",
    "\n",
    "        self.ch_to_idx['\\n'] = 0\n",
    "        self.idx_to_ch[0] = '\\n'\n",
    "\n",
    "        for i in range(26):\n",
    "            curch = chr(i + 97)\n",
    "            self.ch_to_idx[curch] = i + 1\n",
    "            self.idx_to_ch[i + 1] = curch\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        line = self.lines[index]\n",
    "        x_str = ' ' + line  # add a space at the beginning, which indicates a vector of zeros.\n",
    "        y_str = line + '\\n'\n",
    "        x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
    "        y = torch.empty(len(x_str), dtype=torch.long)\n",
    "\n",
    "        y[0] = self.ch_to_idx[y_str[0]]\n",
    "        #we start from the second character because the first character of x was nothing(vector of zeros).\n",
    "        for i, (x_ch, y_ch) in enumerate(zip(x_str[1:], y_str[1:]), 1):\n",
    "            x[i][self.ch_to_idx[x_ch]] = 1\n",
    "            y[i] = self.ch_to_idx[y_ch]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\npamparaptor\n1536\n27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          1., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 1., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          1., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n tensor([16,  1, 13, 16,  1, 18,  1, 16, 20, 15, 18,  0]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do some test on the dataset\n",
    "dset_test = DinosDataset()\n",
    "print(dset_test.ch_to_idx)\n",
    "print(dset_test.lines[1016])\n",
    "print(len(dset_test))\n",
    "print(dset_test.vocab_size)\n",
    "dset_test[1016]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, inputsize):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=inputsize,\n",
    "            hidden_size=inputsize,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, h_state):\n",
    "        r_out, h_state = self.rnn(x, h_state)\n",
    "        return r_out, h_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,2,2,3,2,3,2,3,3,2,2,0,2,3,2,2,2,0,2,2,"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do some test on random choice API\n",
    "prob = np.array([0.1, 0, 0.4, 0.5])\n",
    "\n",
    "for i in range(20):\n",
    "    smplindx = np.random.choice(range(len(prob)), p=prob.ravel())\n",
    "    print(smplindx, end=\",\")\n",
    "    \n",
    "tensortest=torch.Tensor([1,2,3]).float()\n",
    "np.array(tensortest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def sample(model: RNN):\n",
    "    # my comment: notify in eval mode now\n",
    "    model.eval()\n",
    "\n",
    "    word_size = 0\n",
    "    newline_idx = trn_ds.ch_to_idx['\\n']\n",
    "    indices = []\n",
    "    pred_char_idx = -1\n",
    "\n",
    "    # Step 1: initialize first input and hidden state ---all zero---\n",
    "    h_prev = torch.zeros(trn_ds.vocab_size, dtype=torch.float)\n",
    "    x = torch.zeros(trn_ds.vocab_size, dtype=torch.float)\n",
    "\n",
    "    # my comment: with torch.no_grad() is to stop autograd to speed up a bit\n",
    "    with torch.no_grad():\n",
    "        while pred_char_idx != newline_idx and word_size != 50:\n",
    "            # Step 2: Forward propagate x using the equations (1), (2) and (3)\n",
    "            x, h_prev = model.forward(x, h_prev)\n",
    "\n",
    "            np.random.seed(np.random.randint(1, 5000))\n",
    "            # Step 3: Sample the index of a character within the vocabulary from the probability distribution\n",
    "            idx = np.random.choice(range(x.size(0)), p=np.array(x).ravel())\n",
    "            indices.append(idx)\n",
    "\n",
    "            # Step 4: Overwrite the input character as the one corresponding to the sampled index.            \n",
    "            x = trn_ds[idx]\n",
    "            pred_char_idx = idx\n",
    "            word_size += 1\n",
    "        if word_size == 50:\n",
    "            indices.append(newline_idx)\n",
    "    return indices\n",
    "\n",
    "def print_sample(sample_idxs):\n",
    "    print(trn_ds.idx_to_ch[sample_idxs[0]].upper(), end='')\n",
    "    [print(trn_ds.idx_to_ch[x], end='') for x in sample_idxs[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model: RNN, loss_fn, optimizer):\n",
    "    # Go through the training examples one at a time\n",
    "    for line_num, (x, y) in enumerate(trn_dl):\n",
    "        # my comment: it should means switching to training mode\n",
    "        model.train()\n",
    "\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Initialize parameters\n",
    "        h_prev = torch.zeros([1, 1, trn_ds.vocab_size], dtype=torch.float)\n",
    "        print(line_num, h_prev.size(), x.shape[1])\n",
    "        outval, h_prev = model.forward(x, h_prev)\n",
    "        print('outval is ',outval.size())\n",
    "        print(h_prev)\n",
    "        print('y is',y)\n",
    "\n",
    "        for i in range(x.shape[1]):\n",
    "            # Forward propagate through the RNN to compute the loss\n",
    "            #outval, h_prev = model.forward(x[:, i, :], h_prev)\n",
    "            y_correct = torch.zeros(trn_ds.vocab_size).long()\n",
    "            print('yc size',y_correct.size())\n",
    "            y_correct[y[0,i]] = 1\n",
    "            print('ycorrect is',y_correct)\n",
    "            print('outval is',outval[0, i, :])\n",
    "            loss += loss_fn(outval[0, i, :], y_correct)\n",
    "\n",
    "        # Every 100 steps of stochastic gradient descent, \n",
    "        # print one sampled name to see how the algorithm is doing\n",
    "        if (line_num + 1) % 100 == 0:\n",
    "            print_sample(sample(model))\n",
    "\n",
    "        # Backpropagate through time\n",
    "        loss /= x.shape[1]\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip your gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "trn_ds = DinosDataset()\n",
    "trn_dl = DataLoader(trn_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "def train(trn_ds, trn_dl, epochs=1):\n",
    "    model = RNN(trn_ds.vocab_size)\n",
    "    \n",
    "    # Use cross entropy loss\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Use Adam\n",
    "    learning_rate = 0.25\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for e in range(1, epochs + 1):\n",
    "        print(f'{\"-\" * 20} Epoch {e} {\"-\" * 20}')\n",
    "        train_one_epoch(model, loss_fn, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 1 --------------------\n0 torch.Size([1, 1, 27]) 11\noutval is  tensor([[[ 5.9775e-02,  1.8931e-01,  1.8563e-01,  6.1532e-02,  1.8203e-01,\n           1.4274e-01, -2.4255e-01, -1.6399e-01, -1.5501e-02, -1.4280e-01,\n          -6.5196e-02, -2.0958e-01,  2.0335e-01,  4.3502e-02, -1.5821e-01,\n          -5.3852e-02,  3.4125e-01,  1.6385e-01, -2.3135e-01, -2.0145e-01,\n          -4.2239e-04, -5.1255e-02,  2.8476e-01, -8.5937e-02, -1.3950e-01,\n           5.9038e-02,  4.4407e-02],\n         [ 7.9264e-02,  2.8119e-01,  1.9655e-01,  2.1214e-01,  1.2358e-01,\n           2.1266e-01, -2.4519e-01, -3.9993e-01, -7.8814e-02, -1.6455e-01,\n          -3.3602e-02, -5.2712e-01,  2.3689e-01,  2.5693e-01, -8.6884e-02,\n           2.0516e-01,  9.8495e-02, -7.2084e-02, -3.1777e-01, -1.5901e-01,\n          -7.6558e-02,  2.2232e-01,  2.3959e-01,  1.4449e-01,  5.2015e-02,\n           2.4645e-02, -1.1828e-02],\n         [ 5.6520e-02,  1.3066e-01,  1.0959e-01, -1.0587e-01,  1.2364e-01,\n          -2.5610e-02, -2.7942e-01, -1.6311e-01,  3.0373e-01, -8.8014e-02,\n          -2.3362e-01, -3.6893e-01,  3.3288e-02,  5.8552e-02, -1.0661e-01,\n           1.0366e-01,  1.9635e-01, -1.3236e-02, -3.9037e-01, -1.5322e-01,\n          -7.6450e-02, -1.2168e-01,  1.3153e-02,  2.3743e-01,  3.5010e-02,\n           3.3263e-01, -8.1181e-02],\n         [-7.8773e-02,  2.0091e-01,  3.6298e-01, -1.7447e-02,  2.0557e-01,\n           2.3989e-01, -2.8137e-01, -1.8548e-01,  1.3105e-01, -1.8160e-01,\n          -7.8737e-02, -2.6465e-01, -1.4474e-02, -1.2001e-01, -2.0695e-01,\n          -9.9807e-02,  4.1721e-01,  1.0527e-01, -4.1957e-01, -9.5200e-03,\n           3.0417e-02,  1.4639e-01,  1.6535e-01,  2.9332e-01,  2.9055e-02,\n           2.8220e-01,  1.4286e-01],\n         [ 1.6825e-01,  3.2724e-01,  2.7099e-01,  2.3986e-01,  1.6663e-01,\n           2.7777e-01, -1.8704e-01, -2.0759e-01, -2.5540e-02, -6.1254e-02,\n          -5.0622e-02, -5.2192e-01,  2.6140e-01,  2.7411e-02, -3.3083e-01,\n           2.6404e-02,  4.4952e-01,  4.2707e-03, -4.0261e-01, -1.2817e-01,\n           1.3176e-01,  1.1541e-01,  2.5169e-01,  8.2072e-03,  2.3413e-02,\n           8.0153e-02,  2.7405e-01],\n         [ 1.3401e-01,  4.4586e-01,  4.3899e-02,  1.0495e-01,  1.9883e-01,\n           1.5547e-01, -3.6773e-01, -3.4814e-01,  1.6913e-01, -1.6506e-01,\n          -1.4889e-01, -3.9613e-01,  2.2804e-01, -1.4626e-02, -7.0256e-02,\n          -2.3211e-02,  1.5526e-01,  1.2748e-01, -3.0380e-01, -1.1363e-01,\n          -2.4853e-01,  8.7125e-02,  2.0921e-01,  3.5552e-01, -4.6664e-02,\n           3.4078e-01,  2.2923e-02],\n         [ 2.7847e-02,  1.3709e-01,  3.6962e-01,  3.0500e-02,  3.0391e-02,\n           1.3811e-01, -4.4569e-01, -3.2350e-01, -6.8790e-02, -1.7429e-01,\n          -5.7763e-02, -5.5692e-01,  3.2696e-01, -6.2241e-02, -2.5176e-01,\n           2.5392e-01,  3.1007e-01, -9.1585e-02, -3.3734e-01, -5.6208e-02,\n          -4.9641e-02,  1.3566e-01,  2.2453e-01,  2.7499e-01, -3.7229e-02,\n           2.8974e-01,  8.7039e-02],\n         [-7.6232e-02,  3.1530e-01,  8.3665e-02,  3.9488e-02,  2.5994e-01,\n           2.8853e-01, -2.4160e-01, -2.9675e-01,  1.3214e-01, -1.3205e-01,\n          -2.6989e-01, -4.6883e-01, -1.0025e-01, -3.0566e-02, -1.6139e-01,\n           2.0197e-01,  4.4741e-01, -1.9421e-01, -6.3898e-02, -2.6737e-01,\n           6.9586e-02,  2.4024e-01,  1.1329e-01, -4.7202e-02, -1.4022e-01,\n           1.7385e-01,  2.1915e-01],\n         [ 1.7789e-01,  2.0845e-01,  7.1369e-02, -1.4208e-01,  3.9907e-02,\n           3.2732e-01, -2.4176e-01, -4.5579e-01, -5.0132e-03, -8.4304e-02,\n          -4.7585e-02, -3.9913e-01,  2.9967e-01,  4.2737e-02, -1.5411e-01,\n          -1.2390e-01,  3.1582e-01,  9.6859e-02, -1.4764e-01,  4.6150e-03,\n          -3.4700e-01,  1.0183e-01,  1.7562e-01,  2.2416e-01, -7.8218e-02,\n           1.9462e-01,  1.3754e-01],\n         [-2.6070e-02,  2.3230e-01,  2.3645e-01,  1.3639e-01,  4.3981e-02,\n           2.1348e-01, -2.4323e-01, -2.8261e-01,  2.9067e-02,  1.2156e-01,\n          -3.3718e-02, -5.5317e-01, -7.7402e-02, -1.8017e-01, -4.5467e-01,\n           4.4668e-02,  3.6021e-01,  3.9493e-02, -1.7634e-01, -2.2981e-02,\n          -9.5649e-03,  9.9787e-02,  4.5307e-01,  3.8912e-02, -1.1806e-01,\n           1.1997e-01,  6.7555e-03],\n         [ 1.0293e-01,  3.3260e-01, -7.8278e-02, -5.5466e-02,  9.5664e-02,\n           1.3881e-01, -3.6794e-01, -2.6681e-01,  8.4518e-02, -8.8598e-02,\n          -1.9829e-01, -3.2343e-01,  9.9462e-02,  1.4552e-02, -1.1251e-01,\n          -1.9133e-02,  1.1805e-01,  1.0973e-01, -2.7201e-01, -4.8646e-02,\n          -1.9225e-01,  9.9163e-02,  3.1794e-01,  3.2981e-01, -4.8728e-02,\n           3.0033e-01,  2.7708e-02]]], grad_fn=<TransposeBackward0>)\ntensor([[[ 0.1029,  0.3326, -0.0783, -0.0555,  0.0957,  0.1388, -0.3679,\n          -0.2668,  0.0845, -0.0886, -0.1983, -0.3234,  0.0995,  0.0146,\n          -0.1125, -0.0191,  0.1181,  0.1097, -0.2720, -0.0486, -0.1922,\n           0.0992,  0.3179,  0.3298, -0.0487,  0.3003,  0.0277]]],\n       grad_fn=<StackBackward>)\ny is tensor([[ 3,  5, 18,  1, 19,  9, 14, 15, 16, 19,  0]])\nyc size torch.Size([27])\nycorrect is tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0])\noutval is tensor([ 0.0598,  0.1893,  0.1856,  0.0615,  0.1820,  0.1427, -0.2426, -0.1640,\n        -0.0155, -0.1428, -0.0652, -0.2096,  0.2033,  0.0435, -0.1582, -0.0539,\n         0.3412,  0.1639, -0.2314, -0.2015, -0.0004, -0.0513,  0.2848, -0.0859,\n        -0.1395,  0.0590,  0.0444], grad_fn=<SliceBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-4d60f9da4b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-827c33f95747>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trn_ds, trn_dl, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{\"-\" * 20} Epoch {e} {\"-\" * 20}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-147b183d911b>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ycorrect is'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outval is'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Every 100 steps of stochastic gradient descent,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\pengyang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\pengyang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\pengyang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\pengyang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#Start training\n",
    "train(trn_ds, trn_dl, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl]",
   "language": "python",
   "name": "conda-env-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
